---
title: "Attrition RMD"
author: "Samuel"
date: "8/4/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r environment libraries, echo=FALSE}
library(tidyverse)
library(corrplot)
library(mlbench)
library(caret)
library(skimr)
library(mice)
library(purrr)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(class)
library(e1071)
library(grid)
library(tidyr)
library(stringr)
library(naniar)

```

# Build a model for Attrition 

# Start by Tidying and Exploring the dT
I am cheking for the Correlation, the Trends and the Causation

# Remove missing values if available in data set
# Seperate continous variables from categorical variables
# Remove  unwnted variables remove from the list
# Check and make sure categorical variables are stored as factors.
# Remove  highly correlated numeric variables as they tends to interpret the same message
# Perform EDA on  Numeric vs Categorical
# Perform EDA on  Categorical vs Categorical
# KNN Model V

```{r}
dfTrain <- read.csv("CaseStudy2-data.csv", header = TRUE, strip.white=TRUE)
dfTrain
head(dfTrain)
skim(dfTrain)
length(dfTrain)
invisible(ncol(dfTrain))
invisible(skim(dfTrain))
```

```{r, echo=FALSE}
#Continuous variables are: 
# "TotalWorkingYears", "TrainingTimesLastYear", "YearsAtCompany","Age", , "HourlyRate", "MonthlyIncome", "MonthlyRate", "NumCompaniesWorked", , "YearsSinceLastPromotion", "YearsWithCurrManager", "StandardHours" "PercentSalaryHike",  "YearsInCurrentRole", "DailyRate", "DistanceFromHome", "EmployeeCount"

#Categorical Variables are:
# "Attrition","Over18" , "MaritalStatus",  "JobRole", "OverTime""EducationField", "Gender", "Department", "BusinessTravel",

# Variabless with Level
# "StockOptionLevel", "WorkLifeBalance" "Education", "JobLevel",  "JobInvolvement", "EnvironmentSatisfaction", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction"


```


# Missing data evaluation {data-background=""}
There is no missing value

```{r NA eval}
vis_miss(dfTrain)
md.pattern(dfTrain)
```

# Remove all zero variance variables, this can be checked using the skim() function

```{r zero variance variables}
invisible(skim(dfTrain))
dfTrain2 <- select(dfTrain, -c("EmployeeCount", "Over18", "StandardHours"))
skim(dfTrain2)
ncol(dfTrain2)
```


# Remove unwanted variables

```{r}

dfTrain3 <- select(dfTrain2, -c("EmployeeNumber", "ID", "PerformanceRating"))
skim(dfTrain3)
ncol(dfTrain3)

```

# Check if all categorical variables are stored as factors, if not then convert all categorical variables to factors
# The categorical variables are; "Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "Over18", "OverTime"


# Storing all level numeric variables as factors

```{r level variables}
# Categorical Variables
skim(dfTrain3)

dfTrain3$Education <- as.factor(dfTrain3$Education)
dfTrain3$EnvironmentSatisfaction <- as.factor(dfTrain3$EnvironmentSatisfaction)
dfTrain3$JobLevel <- as.factor(dfTrain3$JobLevel)
dfTrain3$JobInvolvement <- as.factor(dfTrain3$JobInvolvement)
dfTrain3$JobSatisfaction <- as.factor(dfTrain3$JobSatisfaction)
dfTrain3$RelationshipSatisfaction <- as.factor(dfTrain3$RelationshipSatisfaction)
dfTrain3$StockOptionLevel <- as.factor(dfTrain3$StockOptionLevel)
dfTrain3$WorkLifeBalance <- as.factor(dfTrain3$WorkLifeBalance)

skim(dfTrain3)
ncol(dfTrain3)
```

# Checking to see the correlation on numeric variables
- Highly correlated relationships
  - Total Working Years v Monthly Income: .78
  - Years at Company v Years in Current Role .78
  - Years at Company v Years with Current Manager .77
  - Years at Company v Total Working Years .64
  - Years at Company v Years Since Last Promotion .64
  - Years with Current Manager v Years in Current Role .71
  - Age vs Tota Working Years 65%
  

```{r high correlation}
corrdfTrain <- dfTrain3
# This table shows the correlation between the numerical variables
corrdfTraintable <- corrdfTrain %>% keep(is.numeric) %>% na.omit %>% cor %>% view

corrdfTrain %>% keep(is.numeric) %>% na.omit %>% cor %>% corrplot("upper", addCoef.col = "black", number.digits = 2, number.cex = 0.5, method="shade", order="hclust", tl.srt=45, tl.cex = 0.8)
invisible(view(corrdfTraintable))
```

# Correlation Review
- Reviewing the correlated variables we can logically conclude some of these are saying similar things. However, the high correlation doesn't tell the whole story. We will keep investigating to get a better picture of these variables and their importance to Attrition.
  - Keep: "MonthlyIncome", "YearsInCurrentRole", "YearsSinceLastPromotion", "YearsAtCompany", "TotalWorkingYears", "YearsWithCurrManager"
  - Drop: "YearsatCompany"
  
```{r}
skim(dfTrain3)

dfTrain3 <- select(dfTrain3, -c("YearsAtCompany"))
skim(dfTrain3)
ncol(dfTrain3)
```

# EDA Numerical variables vs Categorical variables
#Comparison of Attrition (the variable of interest) to categorical variables left in model
  - Colored by Attrition
  - If density plot shows peaks in separate areas then important variable
  - If density plot shows peaks in the same spot (clean overlay) then not an important variable

```{r Automated EDA: Numeric v  Catgorical: all at once}
# 1. Name target variable
Attr <- "Attrition"

# 2. Name explanatory variable
ExplVar<- dfTrain3 %>% keep(is.numeric) %>% colnames

# 3. Create function
PlotFunc <- function(df, explanatory, response) {
  ggplot(data = df) + geom_density(aes_string(x = explanatory, fill = response), alpha = 0.5) + xlab(explanatory) + ylab("Attrition")
}

  # Density plot
PlotFunc(dfTrain3, explanatory =  "TotalWorkingYears", response = "Attrition")

# 4. Create plot list for plot_grid function to reference
PlotList <- lapply(numvariables, function(x) PlotFunc(dfTrain3, x, Attr))

#  Grid of all categorical variables plotted against Attrition
plot_grid(plotlist = PlotList)
```

# After Numeric v Categorical Review
# Get rid of variables that have similar trends
# Remove variables that show the Yes and No of Attrition having the same patterns
- Keep variables that are showing opposite peaks as in the graphs
    - "MonthlyIncome", "YearsInCurrentRole", "NumCompaniesWorked", "Age"

```{r}

dfTrain4 <- select(dfTrain3, -c("TrainingTimesLastYear", "PercentSalaryHike", "DistanceFromHome", "DailyRate", "HourlyRate", "TotalWorkingYears", "MonthlyRate", "YearsWithCurrManager", "YearsSinceLastPromotion"))
skim(dfTrain4)
ncol(dfTrain4)
```


### 8. Categorical v Categorical (Attrition)
- Y | Fill
- Comparison of Attrition (dependent variable of interest) to categorical variables in model
- Bar chart with percentages instead of totals
  - Colored by Attrition
  - If bar chart shows a large difference within the levels/categories of the y variable then it is identified as an important variable to include in the model
  - If bar chart shows a small or zero difference within the levels/categories of the y variable then it is not an important variable to include in the model

```{r Categorical v Categorical (Attrition)}
str(dfTrain4)
dfTrain4 %>% ggplot() + geom_bar(aes(x = dfTrain4$Education, fill = Attrition), position = "fill", alpha = 0.9) + coord_flip()
```


#### Automated EDA: Categorical v Categorical (Attrition) all at once

```{r Automated EDA: Categorical v Categorical (Attrition) all at once}
# 1. Name target variable
FuncAttr <- "Attrition"

# 2. Name explanatory variable
Func2 <- dfTrain4 %>% keep(is.factor) %>% colnames

# 3. Create function
BarFunc <- function(df, explanatory, response) {
  ggplot(data = df) +geom_bar(aes_string(x = explanatory, fill = response), position = "fill", alpha = 0.9) + coord_flip() + xlab(explanatory)
}

  # Example of working function above
  #BarFunc(dfTrain4, explanatory = "MaritalStatus", response = "Attrition")


# 4. Create plot list for plot_grid function to reference
plotlist2 <- lapply(Func2, function(x) BarFunc(dfTrain3, x, FuncAttr))

# 5. Grid of all categorical variables plotted against Attrition
plot_grid(plotlist = plotlist2)
```

# Categorical v Categorical Review
# Drop variables that show a small difference within the levels/categories of the response variable and Keep variables that show a large difference within the levels/categories

```{r}
#skim(dfTrain4)

dfTrain5 <- select(dfTrain4, -c("BusinessTravel", "Department", "Education", "EducationField", "EnvironmentSatisfaction", "Gender", "JobRole", "JobSatisfaction", "MaritalStatus", "RelationshipSatisfaction", "JobLevel"))
#skim(dfTrain5)
ncol(dfTrain5)

#view(dfTrain5)
#str(dfTrain5)
dfTrain6 <- dfTrain5 %>% 
  mutate(OverTime = ifelse(OverTime == "No", 0, 1))
dfTrain6 <- dfTrain5 %>%
  mutate(Attrition = ifelse(Attrition ==  "No", 0, 1))
#view(dfTrain6)
```


***
#Let's narrow down on the variables by using KNN 
- Categorical: "JobInvolvement", "JobLevel", "OverTime", "StockOptionLevel", "WorkLifeBalance"
- Numerical: "Age", "MonthlyIncome", "NumCompaniesWorked", "YearsInCurrentRole"

### Review of multiple models
```{r}
set.seed(8)
splitPerc = .8
trnInddfTrain = sample(1:dim(dfTrain6)[1], round(splitPerc * dim(dfTrain6)[1]))

traindfTrain = dfTrain6[trnInddfTrain,]

testdfTrain = dfTrain6[-trnInddfTrain,]
```

#### 1. Age, Job Involvement, Job Level

```{r}
#invisible(knn(traindfTrain[,c(1,3,4)], testdfTrain[,c(1,3,4)], traindfTrain$Attrition, prob = TRUE, k=19))
#classificationdfTrain = knn(traindfTrain[,c(1,3,4)], testdfTrain[,c(1,3,4)], traindfTrain$Attrition, prob = TRUE, k=19)
#CMdfTrain1.1 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#CMdfTrain1.1
```




#### 2. Job Involvement, Monthly Income, Number Companies Worked

```{r Job Involvement, Monthly Income, Number Companies Worked}
#invisible(knn(traindfTrain[,c(3,4,5)], testdfTrain[,c(3,4,5)], traindfTrain$Attrition, prob = TRUE, k=19))
#classificationdfTrain = knn(traindfTrain[,c(3,4,5)], testdfTrain[,c(3,4,5)], traindfTrain$Attrition, prob = TRUE, k=19)
#CMdfTrain2 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#CMdfTrain2
```

#### 3. Monthly Income, Number of Companies Worked, Over Time

```{r Monthly Income, Number of Companies Worked}
#invisible(knn(traindfTrain[,c(4,5,6)], testdfTrain[,c(4,5,6)], traindfTrain$Attrition, prob = TRUE, k=7))
#classificationdfTrain = knn(traindfTrain[,c(4,5,6)], testdfTrain[,c(4,5,6)], traindfTrain$Attrition, prob = TRUE, k=7)
#CMdfTrain3 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#CMdfTrain3
```

#### 4. Number of Companies Worked, Over Time, Stock Option Level

```{r Number of Companies Worked, Over Time, Stock Option Level}
#invisible(knn(traindfTrain[,c(5,6,7)], testdfTrain[,c(5,6,7)], traindfTrain$Attrition, prob = TRUE, k=7))
#classificationdfTrain = knn(traindfTrain[,c(5,6,7)], testdfTrain[,c(5,6,7)], traindfTrain$Attrition, prob = TRUE, k=7)
#CMdfTrain5 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#CMdfTrain5
```

#### 5. Over Time, WorkLifeBalance, Years In Current Role

```{r}
#invisible(knn(traindfTrain[,c(6,7,8)], testdfTrain[,c(6,7,8)], traindfTrain$Attrition, prob = TRUE, k=7))
#classificationdfTrain = knn(traindfTrain[,c(6,7,8)], testdfTrain[,c(6,7,8)], traindfTrain$Attrition, prob = TRUE, k=7)
#CMdfTrain6 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#CMdfTrain6
```


#### 6. Stock Option Level, Work Life Balance, Age

```{r}
#invisible(knn(traindfTrain[,c(7,8,1)], testdfTrain[,c(7,8,1)], traindfTrain$Attrition, prob = TRUE, k=7))
#classificationdfTrain = knn(traindfTrain[,c(7,8,1)], testdfTrain[,c(7,8,1)], traindfTrain$Attrition, prob = TRUE, k=7)
#CMdfTrain7 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#CMdfTrain7
```

#### 7. Work Life Balance, Years in Current Role, Age

```{r}
#invisible(knn(traindfTrain[,c(8,1,3)], testdfTrain[,c(8,1,3)], traindfTrain$Attrition, prob = TRUE, k= 19))
#classificationdfTrain = knn(traindfTrain[,c(8,1,3)], testdfTrain[,c(8,1,3)], traindfTrain$Attrition, prob = TRUE, k= 19)
#CMdfTrain8 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#CMdfTrain8
```

#### 8. Montly Income (4) Over Time(6) Stock Option Level (7)
```{r}
#invisible(knn(traindfTrain[,c(4,6,7)], testdfTrain[,c(4,6,7)], traindfTrain$Attrition, prob = TRUE, k=19))
#classificationdfTrain = knn(traindfTrain[,c(4,6,7)], testdfTrain[,c(4,6,7)], traindfTrain$Attrition, prob = TRUE, k=19)
#CMdfTrain8 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#CMdfTrain8
```



#### Find best k for Model 7
- Best k: 15 - 23
```{r find best k}
set.seed(8)
splitPerc = .8
trnInddfTrain = sample(1:dim(dfTrain6)[1], round(splitPerc * dim(dfTrain6)[1]))

traindfTrain = dfTrain6[trnInddfTrain,]

testdfTrain = dfTrain6[-trnInddfTrain,]

spec = data.frame(specificity = numeric(30), k = numeric(30))
for (i in 1:30) 
  {
  classificationdfTrain = knn(traindfTrain[,c(8,1,3)], testdfTrain[,c(8,1,3)], traindfTrain$Attrition, prob = TRUE, k=i)
  table(testdfTrain$Attrition, classificationdfTrain)
  CMdfTrain8 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
  spec$specificity[i] = CMdfTrain8$byClass[2]
  spec$k[i] = i
}
plot(spec$k, spec$specificity, type = "l", xlab = "k")
#k <- which.max(spec$specificity)
```

***
#### Final Model (7)

```{r}
invisible(knn(traindfTrain[,c(8,1,3)], testdfTrain[,c(8,1,3)], traindfTrain$Attrition, prob = TRUE, k= 20))
classificationdfTrain = knn(traindfTrain[,c(8,1,3)], testdfTrain[,c(8,1,3)], traindfTrain$Attrition, prob = TRUE, k= 20)
CMdfTrain8 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
CMdfTrain8
```

***
## Final KNN Prediction Model for Attrition
- Attrition is most closely identified by taking into account
  1. Number of companies a person has worked.
  2. If they do or do not have to work overtime.
  3. An employee's stock option level
- Accuracy > 80%
- Sensitivity > 80%
- Specificity = 75%

***
## Competition Set Analysis
```{r}
competition <- read.csv("https://raw.githubusercontent.com/JaclynCoate/MDS-6306-Doing-Data-Science-Fall-2019/Master/Unit%2014%20and%2015%20Case%20Study%202/CaseStudy2CompSet%20No%20Attrition.csv", header = TRUE, strip.white=TRUE)
invisible(competition)
```

## KNN Model Used to Predict Attrition
```{r}
#Work Life Balance, Years in Current Role, Age
competition <- select(competition, c("ID", "WorkLifeBalance", "YearsInCurrentRole", "Age"))

estimates <- data.frame(knn(traindfTrain[,c(8,1,3)], competition[,c(2,3,4)], traindfTrain$Attrition, prob = TRUE, k = 19))
compFinal <- cbind(competition, estimates)
colnames(compFinal)[5] <- "Attrition"

compFinal <- compFinal %>% 
  mutate(Attrition = ifelse(Attrition == 0, "No", "Yes"))
invisible(compFinal)
```

### Checking model results aginst graphical analysis

```{r}
compFinal %>% ggplot(mapping = aes(x = Attrition)) + geom_bar() + ggtitle("Comeptition Set: Attrition Count") + theme_excel_new()

dfTrain %>% ggplot(mapping = aes(x = Attrition)) + geom_bar() + ggtitle("Original Data: Attrition Count") + theme_excel_new()
```

### Checking model results aginst graphical analysis

```{r}
compFinal %>% ggplot() + geom_density(aes(x = Age, fill = Attrition, alpha = .1)) +
  theme_excel_new() + ggtitle("Attrition v Age") + ylab("Attrition") + xlab("Age")
```

### Checking model against graphical analysis

```{r}
compFinal %>% ggplot() + geom_bar(aes(x = WorkLifeBalance, fill = Attrition), position = "fill", alpha = .7) + coord_flip()
```

### Write CSV of fitted Competition Data Set
```{r}
#write_csv(compFinal, "/Users/Jaco/Desktop/SMU/Fall2019/DS_6306_Doing_Data_Science/Unit_14CaseStudy2\\CompetitionSet.csv")
```

# Things I had to walk away from
#### Trying to mean of all three variables

```{r}
#iterations = 100
#numks = 100 
#masterAcc = matrix(nrow = iterations, ncol = numks)
#for(j in 1:iterations) {
#  accs = data.frame(accuracy = numeric(numks), k = numeric(numks))
#  trnInddfTrain = sample(1:dim(dfTrain6)[1], round(splitPerc * dim(dfTrain6)[1]))
#  traindfTrain = dfTrain6[trnInddfTrain,]
#  testdfTrain = dfTrain6[-trnInddfTrain,]
#  for(i in 1:numks) {
#    classificationdfTrain = knn(traindfTrain[,c(8,1,3)], testdfTrain[,c(8,1,3)], traindfTrain$Attrition, prob = TRUE, k=i)
#    table(testdfTrain$Attrition, classificationdfTrain)
#    CMdfTrain8 = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#    masterAcc[j,i] = CMdfTrain8$overall[1]
#  }
#}

#MeanAcc = colMeans(masterAcc)
#plot(seq(1,numks,1),MeanAcc, type = "l")
#k <- which.max(MeanAcc)

#@@@@@@@@@@@@@@@@@@

#iterations = 500
#masterAcc = matrix(nrow = iterations)
#masterSen = matrix(nrow = iterations)
#masterSpec = matrix(nrow = iterations)
#splitPer = .7
#for (j in 1:iterations)
#  {
#  trnInddfTrain = sample(1:dim(dfTrain6)[1],round(splitPerc * dim(dfTrain6)[1]))
#  traindfTrain = dfTrain6[trnInddfTrain,]
#  testdfTrain = dfTrain6[-trnInddfTrain,]
#  
#  classificationdfTrain = knn(traindfTrain[,c(8,1,3)], testdfTrain[,c(8,1,3)], traindfTrain$Attrition, prob = TRUE, k=i)
#  table(testdfTrain$Attrition, classificationdfTrain)
#  
#  CMdfTrainInt = confusionMatrix(table(testdfTrain$Attrition, classificationdfTrain))
#  masterAcc[j] = CMdfTrainInt$overall[1]
#  masterSen[j] = CMdfTrainInt$byClass[1]
#  masterSpec[j] = CMdfTrainInt$byClass[2]
#}

#MeanAccUFrit = colMeans(masterAcc)
#MeanAccUFrit
#MeanSenFrit = colMeans(masterSen)
#MeanSenFrit
#MeanSpecFrit = colMeans(masterSpec)
#MeanSpecFrit
```  




### 10. NaiveBates Model to Reduce Variables
- Categorical: "JobInvolvement", "JobLevel", "OverTime", "StockOptionLevel", "WorkLifeBalance"
- Numerical: "Age", "MonthlyIncome", "NumCompaniesWorked", "YearsInCurrentRole"

#### 1. All Variable

```{r}
#set.seed(4)
#splitPerc = .7
#trnInddfTrain = sample(1:dim(dfTrain5)[1], round(splitPerc * dim(dfTrain5)[1]))
#trnInddfTrain

#traindfTrain = dfTrain6[trnInddfTrain,]
#traindfTrain

#testdfTrain = dfTrain6[-trnInddfTrain,]
#testdfTrain

#nBdfTrain1 <- naiveBayes(Attrition ~ . , data = traindfTrain)

#predict(nBdfTrain1, testdfTrain[,c(1,3,4)], type = "raw")

#table(predict(nBdfTrain1, testdfTrain[,c(1,3,4)], type = "raw"), testdfTrain$Attrition)






#modelU7.s4 <- naiveBayes(Survived ~ . , data =  trainTitanicU7.s4)

#predict(modelU7.s4, testTitanicU7.s4[,c(2,4)], type = "raw")

#table(predict(modelU7.s4, testTitanicU7.s4[,c(2,4)]), testTitanicU7.s4$Survived)

#CMU7.s4 = confusionMatrix(table(predict(modelU7.s4, testTitanicU7.s4[,c(2,4)]), testTitanicU7.s4$Survived))
#CMU7.s4

#knn(trainTitanicU7.s4[,c(2,4)], testTitanicU7.s4[,c(2,4)],trainTitanicU7.s4$Survived, prob = TRUE, k = 11)
#classKNN.s4 = knn(trainTitanicU7.s4[,c(2,4)], testTitanicU7.s4[,c(2,4)],trainTitanicU7.s4$Survived, prob = TRUE, k = 11)
#CMknnU7.s4 = confusionMatrix(table(testTitanicU7.s4$Survived, classKNN.s4))
#CMknnU7.s4
```

```{r}
```

```{r}
```

